# åˆ†å¸ƒå¼è®­ç»ƒæ€§èƒ½å¯¹æ¯”å®éªŒæŒ‡å—

## ğŸ“‹ å®éªŒæ¦‚è¿°

æœ¬å®éªŒå¯¹æ¯”ä¸‰ç§åˆ†å¸ƒå¼è®­ç»ƒæ–¹æ³•çš„æ€§èƒ½ï¼š
1. **Baseline DDP** - PyTorchåŸç”Ÿåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼ˆä½¿ç”¨All-Reduceï¼‰
2. **Manual All-Reduce** - æ‰‹åŠ¨å®ç°çš„All-Reduceæ¢¯åº¦åŒæ­¥
3. **Parameter Server (PS)** - å‚æ•°æœåŠ¡å™¨æ¶æ„ï¼ˆRank 0ä¸ºServerï¼Œå…¶ä½™ä¸ºWorkersï¼‰

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### 1. æ£€æŸ¥GPUå¯ç”¨æ€§
```bash
nvidia-smi
```
ç¡®ä¿è‡³å°‘æœ‰ **4ä¸ªå¯ç”¨GPU**ã€‚

### 2. æ£€æŸ¥å¿…è¦æ–‡ä»¶
ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨ï¼š
- `baseline_multi_card.py` - Baseline DDPè®­ç»ƒè„šæœ¬
- `all_reduce_train.py` - Manual All-Reduceè®­ç»ƒè„šæœ¬
- `ps_train.py` - Parameter Serverè®­ç»ƒè„šæœ¬
- `analyze_results.py` - æ€§èƒ½åˆ†æå’Œå¯è§†åŒ–è„šæœ¬
- `resnet50-0676ba61.pth` - ResNet50é¢„è®­ç»ƒæƒé‡

### 3. æ•°æ®é›†å‡†å¤‡
ç¡®ä¿ImageNetæ•°æ®é›†è·¯å¾„æ­£ç¡®ï¼š
```bash
# æ£€æŸ¥æ•°æ®é›†ç»“æ„
ls -la ./train/
ls -la ./val/
```

å¦‚æœæ•°æ®é›†ä¸åœ¨å½“å‰ç›®å½•ï¼Œéœ€è¦åœ¨è¿è¡Œå‘½ä»¤ä¸­æŒ‡å®š `--data-dir` å‚æ•°ã€‚

### 4. å®‰è£…ä¾èµ–åŒ…ï¼ˆå¦‚æœéœ€è¦ï¼‰
```bash
pip install matplotlib numpy tqdm
```

---

## ğŸš€ è¿è¡Œå®éªŒ

### å®éªŒ A: Baseline DDP (PyTorchåŸç”ŸDDP)

**å‘½ä»¤:**
```bash
torchrun --nproc_per_node=4 baseline_multi_card.py
```

**å¦‚æœéœ€è¦è‡ªå®šä¹‰æ•°æ®è·¯å¾„:**
```bash
torchrun --nproc_per_node=4 baseline_multi_card.py
```
ï¼ˆæ³¨æ„ï¼šæ­¤è„šæœ¬çš„æ•°æ®è·¯å¾„åœ¨ä»£ç å†…éƒ¨é€šè¿‡ `train()` å‡½æ•°çš„ `path` å‚æ•°è®¾ç½®ï¼Œé»˜è®¤ä¸º `./`ï¼‰

**é¢„æœŸè¾“å‡º:**
- æ¯ä¸ªepochçš„è®­ç»ƒè¿›åº¦æ¡ï¼ˆå¸¦lossã€accuracyã€throughputï¼‰
- æ¯ä¸ªepochçš„è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡æ‘˜è¦
- æœ€ç»ˆç”Ÿæˆ `results_baseline_ddp.json`

**è¿è¡Œæ—¶é—´:** çº¦ 10-30 åˆ†é’Ÿï¼ˆå–å†³äºæ•°æ®é›†å¤§å°å’Œç¡¬ä»¶ï¼‰

---

### å®éªŒ B: Manual All-Reduce

**å‘½ä»¤:**
```bash
torchrun --nproc_per_node=4 all_reduce_train.py --epochs 3 --batch-size 64 --workers 16 --data-dir ./ --backend nccl
```

**å‚æ•°è¯´æ˜:**
- `--epochs 3`: è®­ç»ƒ3ä¸ªepoch
- `--batch-size 64`: æ¯ä¸ªè¿›ç¨‹çš„batch size
- `--workers 16`: DataLoaderçš„workeræ•°é‡
- `--data-dir ./`: æ•°æ®é›†æ ¹ç›®å½•
- `--backend nccl`: ä½¿ç”¨NCCLé€šä¿¡åç«¯ï¼ˆGPUå¿…éœ€ï¼‰

**é¢„æœŸè¾“å‡º:**
- æ¯ä¸ªepochçš„è®­ç»ƒè¿›åº¦æ¡ï¼ˆåªæœ‰Rank 0æ˜¾ç¤ºï¼‰
- æ¯ä¸ªepochçš„è®­ç»ƒæŒ‡æ ‡æ‘˜è¦ï¼ˆLossã€Accuracyã€Throughputã€é€šä¿¡æ—¶é—´ï¼‰
- æœ€ç»ˆç”Ÿæˆ `results_all_reduce.json`

**è¿è¡Œæ—¶é—´:** çº¦ 10-30 åˆ†é’Ÿ

---

### å®éªŒ C: Parameter Server

**å‘½ä»¤:**
```bash
torchrun --nproc_per_node=4 ps_train.py --epochs 3 --batch-size 64 --workers 16 --data-dir ./ --backend nccl
```

**å‚æ•°è¯´æ˜:**
- `--epochs 3`: è®­ç»ƒ3ä¸ªepoch
- `--batch-size 64`: æ¯ä¸ªWorkerçš„batch size
- `--workers 16`: DataLoaderçš„workeræ•°é‡
- `--data-dir ./`: æ•°æ®é›†æ ¹ç›®å½•
- `--backend nccl`: ä½¿ç”¨NCCLé€šä¿¡åç«¯

**æ¶æ„è¯´æ˜:**
- **Rank 0**: å‚æ•°æœåŠ¡å™¨ï¼ˆPSï¼‰ï¼Œè´Ÿè´£å‚æ•°å­˜å‚¨å’Œæ›´æ–°
- **Rank 1-3**: Workersï¼Œè´Ÿè´£è®­ç»ƒå’Œæ¢¯åº¦è®¡ç®—
- é€šä¿¡æµç¨‹ï¼šPSå¹¿æ’­å‚æ•° â†’ Workersè®¡ç®—æ¢¯åº¦ â†’ Workerså‘é€æ¢¯åº¦ â†’ PSèšåˆå¹¶æ›´æ–°

**é¢„æœŸè¾“å‡º:**
- Workerç«¯ï¼ˆRank 1ï¼‰æ˜¾ç¤ºè®­ç»ƒè¿›åº¦æ¡å’Œè¯¦ç»†æŒ‡æ ‡
- PSç«¯ï¼ˆRank 0ï¼‰æ˜¾ç¤ºæ‰¹æ¬¡å¤„ç†è¿›åº¦å’Œé€šä¿¡æ—¶é—´ç»Ÿè®¡
- Workersæ˜¾ç¤ºè®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡
- æœ€ç»ˆç”Ÿæˆ `results_ps.json`

**è¿è¡Œæ—¶é—´:** çº¦ 10-30 åˆ†é’Ÿï¼ˆå¯èƒ½æ¯”DDPæ…¢ï¼Œå› ä¸ºé€šä¿¡æ¨¡å¼ä¸åŒï¼‰

---

## ğŸ“Š æ€§èƒ½åˆ†æä¸å¯è§†åŒ–

### è¿è¡Œåˆ†æè„šæœ¬

æ‰€æœ‰ä¸‰ä¸ªå®éªŒå®Œæˆåï¼Œè¿è¡Œåˆ†æè„šæœ¬ç”Ÿæˆå¯¹æ¯”ç»“æœï¼š

```bash
python analyze_results.py
```

**è¾“å‡ºå†…å®¹:**
1. **ç»ˆç«¯è¾“å‡º:**
   - æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ï¼ˆååé‡ã€è®­ç»ƒæ—¶é—´ã€å‡†ç¡®ç‡ï¼‰
   - åŠ é€Ÿæ¯”åˆ†æï¼ˆç›¸å¯¹äºBaseline DDPï¼‰

2. **ç”Ÿæˆçš„å›¾è¡¨** (ä¿å­˜åœ¨ `./plots/` ç›®å½•):
   - `throughput_comparison.png` - ååé‡å¯¹æ¯”æŸ±çŠ¶å›¾
   - `training_time_comparison.png` - è®­ç»ƒæ—¶é—´å¯¹æ¯”æŸ±çŠ¶å›¾
   - `loss_curves.png` - Lossæ”¶æ•›æ›²çº¿å¯¹æ¯”
   - `accuracy_curves.png` - å‡†ç¡®ç‡æ›²çº¿å¯¹æ¯”
   - `communication_overhead.png` - é€šä¿¡å¼€é”€å¯¹æ¯”ï¼ˆPS vs All-Reduceï¼‰

3. **æ–‡æœ¬æŠ¥å‘Š:**
   - `performance_report.txt` - è¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š

---

## ğŸ“ˆ ç»“æœæ–‡ä»¶è¯´æ˜

### JSONç»“æœæ–‡ä»¶ç»“æ„

æ¯ä¸ªå®éªŒä¼šç”Ÿæˆä¸€ä¸ªJSONæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

**`results_baseline_ddp.json`:**
```json
{
  "method": "Baseline DDP (PyTorch)",
  "world_size": 4,
  "batch_size": 64,
  "start_time": "2025-12-12 10:00:00",
  "end_time": "2025-12-12 10:15:00",
  "epochs": [
    {
      "epoch": 1,
      "train_loss": 0.5234,
      "train_accuracy": 85.23,
      "train_time": 300.5,
      "train_throughput": 512.3,
      "avg_batch_time": 0.125,
      "val_loss": 0.4567,
      "val_accuracy": 87.45
    }
  ],
  "summary": {
    "avg_train_throughput": 510.2,
    "avg_train_time_per_epoch": 305.3,
    "best_val_accuracy": 88.67
  },
  "all_losses": [...]
}
```

**`results_all_reduce.json`:**
```json
{
  "method": "Manual All-Reduce",
  "world_size": 4,
  "batch_size": 64,
  "epochs": [
    {
      "epoch": 1,
      "train_loss": 0.5123,
      "train_accuracy": 85.67,
      "train_time": 310.2,
      "train_throughput": 498.3,
      "avg_batch_time": 0.128,
      "avg_comm_time": 0.015,
      "all_losses": [...]
    }
  ],
  "summary": {
    "avg_train_throughput": 495.6,
    "avg_train_time_per_epoch": 312.1,
    "final_train_accuracy": 86.23
  }
}
```

**`results_ps.json`:**
```json
{
  "method": "Parameter Server (PS)",
  "world_size": 4,
  "num_workers": 3,
  "batch_size": 64,
  "epochs": [
    {
      "epoch": 1,
      "train_loss": 0.5345,
      "train_accuracy": 84.56,
      "train_time": 350.8,
      "train_throughput": 440.2,
      "avg_batch_time": 0.145,
      "avg_comm_time_pull": 0.025,
      "avg_comm_time_push": 0.018,
      "val_loss": 0.4789,
      "val_accuracy": 86.34
    }
  ],
  "summary": {
    "avg_train_throughput": 438.5,
    "avg_train_time_per_epoch": 352.3,
    "avg_comm_time_pull": 0.024,
    "avg_comm_time_push": 0.019,
    "best_val_accuracy": 87.12
  },
  "all_losses": [...]
}
```

---

## ğŸ“ æ’°å†™æŠ¥å‘ŠæŒ‡å—

### Section 3.2 (Implementation) - å®ç°ç»†èŠ‚

#### Parameter Server æ¶æ„åˆ†æ

**1. æ‹“æ‰‘ç»“æ„:**
```
è§’è‰²åˆ†é…:
- Rank 0: Parameter Server (PS)
  - å­˜å‚¨å…¨å±€æ¨¡å‹å‚æ•°
  - æ¥æ”¶æ‰€æœ‰Workersçš„æ¢¯åº¦
  - èšåˆæ¢¯åº¦å¹¶æ›´æ–°å‚æ•°
  
- Rank 1-N: Workers
  - åŠ è½½æ•°æ®å¹¶è¿›è¡Œå‰å‘ä¼ æ’­
  - è®¡ç®—æ¢¯åº¦
  - ä¸PSè¿›è¡Œå‚æ•°å’Œæ¢¯åº¦é€šä¿¡
```

**å…³é”®ä»£ç ä½ç½® (ps_train.py):**
- **è§’è‰²åˆ¤å®š**: ç¬¬20è¡Œ `is_ps = (rank == 0)`
- **å‚æ•°æ‹‰å–**: ç¬¬120-122è¡Œ (Workersä»PSæ¥æ”¶å‚æ•°)
  ```python
  for param in model.parameters():
      dist.recv(param.data, src=0)
  ```
- **æ¢¯åº¦æ¨é€**: ç¬¬136-138è¡Œ (Workerså‘é€æ¢¯åº¦ç»™PS)
  ```python
  for param in model.parameters():
      dist.send(param.grad.data, dst=0)
  ```
- **å‚æ•°å¹¿æ’­**: ç¬¬178-181è¡Œ (PSå‘é€å‚æ•°ç»™æ‰€æœ‰Workers)
  ```python
  for param in model.parameters():
      for worker_rank in range(1, world_size):
          dist.send(param.data, dst=worker_rank)
  ```
- **æ¢¯åº¦èšåˆ**: ç¬¬184-193è¡Œ (PSæ¥æ”¶å¹¶å¹³å‡æ¢¯åº¦)
  ```python
  for param in model.parameters():
      grad_data = torch.zeros_like(param.data)
      for worker_rank in range(1, world_size):
          worker_grad = torch.zeros_like(param.data)
          dist.recv(worker_grad, src=worker_rank)
          grad_data += worker_grad
      grad_data /= num_workers
      param.grad = grad_data
  ```

**2. é€šä¿¡æµç¨‹ (åŒæ­¥PS):**
```
æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡:
1. PS â†’ Workers: å¹¿æ’­æœ€æ–°å‚æ•°
2. Workers: æœ¬åœ°å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
3. Workers â†’ PS: å‘é€æ¢¯åº¦
4. PS: èšåˆæ¢¯åº¦ (æ±‚å¹³å‡)
5. PS: æ›´æ–°å‚æ•°
6. é‡å¤æ­¥éª¤1
```

**3. ä¼˜åŒ–ç‚¹åˆ†æ:**

åŸå§‹ä»£ç çš„é—®é¢˜ï¼š
- ä½¿ç”¨é€å‚æ•°é€Workerçš„ç‚¹å¯¹ç‚¹é€šä¿¡ï¼ˆ`dist.send/recv`ï¼‰ï¼Œæ•ˆç‡è¾ƒä½
- æ²¡æœ‰ä½¿ç”¨PyTorchçš„é›†åˆé€šä¿¡åŸè¯­ï¼ˆ`broadcast`, `reduce`ï¼‰
- æ¯ä¸ªå‚æ•°éƒ½å•ç‹¬é€šä¿¡ï¼Œæ— æ³•åˆ©ç”¨æ‰¹é‡ä¼ è¾“ä¼˜åŠ¿

æ”¹è¿›å»ºè®®ï¼š
- ä½¿ç”¨ `dist.broadcast()` æ›¿ä»£å¾ªç¯å‘é€å‚æ•°
- ä½¿ç”¨ `dist.reduce()` èšåˆæ¢¯åº¦
- è€ƒè™‘å‚æ•°æ‰“åŒ…ä¼ è¾“å‡å°‘é€šä¿¡æ¬¡æ•°

---

### Section 4.2 (Evaluation) - æ€§èƒ½è¯„ä¼°

#### å¯¹æ¯”è¡¨æ ¼æ¨¡æ¿

ä» `performance_report.txt` æˆ–ç»ˆç«¯è¾“å‡ºæå–æ•°æ®ï¼Œå¡«å…¥ä»¥ä¸‹è¡¨æ ¼ï¼š

| æ–¹æ³• | å¹³å‡ååé‡ (img/s) | å¹³å‡è®­ç»ƒæ—¶é—´/epoch (s) | æœ€ä½³å‡†ç¡®ç‡ (%) | ç›¸å¯¹åŠ é€Ÿæ¯” |
|------|-------------------|----------------------|--------------|----------|
| Baseline DDP | XXX.XX | XXX.XX | XX.XX | 1.00x (åŸºå‡†) |
| Manual All-Reduce | XXX.XX | XXX.XX | XX.XX | X.XXx |
| Parameter Server | XXX.XX | XXX.XX | XX.XX | X.XXx |

#### é€šä¿¡å¼€é”€å¯¹æ¯”

ä»ç»“æœJSONä¸­æå–ï¼š

| æ–¹æ³• | å‚æ•°æ‹‰å– (ms) | æ¢¯åº¦æ¨é€ (ms) | All-Reduce (ms) | æ€»é€šä¿¡æ—¶é—´ (ms) |
|------|-------------|--------------|----------------|----------------|
| Baseline DDP | - | - | - | (éšå¼ï¼Œç”±PyTorchå¤„ç†) |
| Manual All-Reduce | - | - | XX.XX | XX.XX |
| Parameter Server | XX.XX | XX.XX | - | XX.XX + XX.XX |

#### åˆ†æè¦ç‚¹

1. **ååé‡åˆ†æ:**
   - DDPé€šå¸¸æœ€å¿«ï¼ˆä½¿ç”¨é«˜åº¦ä¼˜åŒ–çš„NCCL All-Reduceï¼‰
   - PSå¯èƒ½è¾ƒæ…¢ï¼ˆç‚¹å¯¹ç‚¹é€šä¿¡å¼€é”€å¤§ï¼‰
   - è§£é‡Šå·®å¼‚åŸå› 

2. **æ”¶æ•›æ€§åˆ†æ:**
   - å¯¹æ¯”Lossæ›²çº¿å›¾
   - ä¸‰ç§æ–¹æ³•çš„æ”¶æ•›é€Ÿåº¦æ˜¯å¦ä¸€è‡´ï¼Ÿ
   - æœ€ç»ˆå‡†ç¡®ç‡å·®å¼‚

3. **é€šä¿¡æ•ˆç‡:**
   - PSçš„é€šä¿¡æ˜¯åŒæ­¥ä¸”ä¸²è¡Œçš„
   - All-Reduceå¯ä»¥åˆ©ç”¨æ ‘å½¢æ‹“æ‰‘å’Œå¸¦å®½èšåˆ
   - ä»å›¾è¡¨ `communication_overhead.png` ä¸­åˆ†æ

4. **å¯æ‰©å±•æ€§:**
   - PSæ¶æ„åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹çš„ç“¶é¢ˆï¼ˆå•ç‚¹PSï¼‰
   - DDPçš„æ‰©å±•æ€§æ›´å¥½

---

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**1. CUDA Out of Memory**
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°batch size
torchrun --nproc_per_node=4 ps_train.py --batch-size 32
```

**2. æ•°æ®é›†è·¯å¾„é”™è¯¯**
```bash
# æ£€æŸ¥æ•°æ®é›†
ls ./train/ ./val/

# æˆ–æŒ‡å®šæ­£ç¡®è·¯å¾„
torchrun --nproc_per_node=4 ps_train.py --data-dir /path/to/imagenet
```

**3. NCCLé€šä¿¡è¶…æ—¶**
```bash
# å¢åŠ è¶…æ—¶æ—¶é—´
export NCCL_TIMEOUT=1800
torchrun --nproc_per_node=4 ps_train.py
```

**4. å¯è§†åŒ–è„šæœ¬æŠ¥é”™ï¼ˆç¼ºå°‘matplotlibï¼‰**
```bash
pip install matplotlib numpy
```

**5. æƒé‡æ–‡ä»¶ä¸å­˜åœ¨**
```python
# ä¿®æ”¹è„šæœ¬ä½¿ç”¨åœ¨çº¿ä¸‹è½½ï¼ˆå¦‚æœç½‘ç»œå…è®¸ï¼‰
# å°† model = models.resnet50(weights=None) å’Œ state_dictåŠ è½½éƒ¨åˆ†
# æ”¹ä¸ºï¼š
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
```

---

## ğŸ“¤ æäº¤ææ–™æ¸…å•

å®éªŒå®Œæˆåï¼Œå‡†å¤‡ä»¥ä¸‹æ–‡ä»¶ç”¨äºæŠ¥å‘Šï¼š

### å¿…éœ€æ–‡ä»¶:
1. âœ… `results_baseline_ddp.json`
2. âœ… `results_all_reduce.json`
3. âœ… `results_ps.json`
4. âœ… `performance_report.txt`
5. âœ… `plots/` ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾è¡¨ï¼š
   - `throughput_comparison.png`
   - `training_time_comparison.png`
   - `loss_curves.png`
   - `accuracy_curves.png`
   - `communication_overhead.png`

### æºä»£ç ï¼ˆå·²ä¼˜åŒ–ï¼‰:
6. âœ… `baseline_multi_card.py`
7. âœ… `all_reduce_train.py`
8. âœ… `ps_train.py`
9. âœ… `analyze_results.py`

### æŠ¥å‘Šå†…å®¹å»ºè®®:

**Section 3.2 (Implementation):**
- Parameter Serveræ¶æ„å›¾
- å…³é”®ä»£ç ç‰‡æ®µï¼ˆè§’è‰²åˆ†é…ã€é€šä¿¡æµç¨‹ï¼‰
- ä¸DDPçš„æ¶æ„å¯¹æ¯”

**Section 4.2 (Evaluation):**
- æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
- ååé‡å’Œè®­ç»ƒæ—¶é—´å¯¹æ¯”å›¾
- Lossæ”¶æ•›æ›²çº¿å›¾
- é€šä¿¡å¼€é”€åˆ†æ
- ç»“è®ºä¸åˆ†æ

---

## ğŸ¯ å¿«é€Ÿå®éªŒæµç¨‹ï¼ˆå®Œæ•´å‘½ä»¤ï¼‰

å¦‚æœä¸€åˆ‡ç¯å¢ƒå°±ç»ªï¼Œå¯ä»¥æŒ‰é¡ºåºæ‰§è¡Œï¼š

```bash
# 1. æ¸…ç†æ—§ç»“æœ
rm -f results_*.json performance_report.txt
rm -rf plots/

# 2. è¿è¡Œä¸‰ä¸ªå®éªŒï¼ˆä¾æ¬¡æ‰§è¡Œï¼Œæ¯ä¸ªçº¦10-30åˆ†é’Ÿï¼‰
echo "Running Baseline DDP..."
torchrun --nproc_per_node=4 baseline_multi_card.py

echo "Running Manual All-Reduce..."
torchrun --nproc_per_node=4 all_reduce_train.py --epochs 3 --batch-size 64 --workers 16 --data-dir ./ --backend nccl

echo "Running Parameter Server..."
torchrun --nproc_per_node=4 ps_train.py --epochs 3 --batch-size 64 --workers 16 --data-dir ./ --backend nccl

# 3. åˆ†æç»“æœ
echo "Analyzing results..."
python analyze_results.py

# 4. æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶
echo "Generated files:"
ls -lh results_*.json performance_report.txt plots/*.png
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š
1. æ£€æŸ¥æœ¬æ–‡æ¡£çš„"æ•…éšœæ’æŸ¥"ç« èŠ‚
2. æŸ¥çœ‹è„šæœ¬å†…çš„è¯¦ç»†æ—¥å¿—è¾“å‡º
3. ç¡®è®¤GPUå’Œæ•°æ®é›†é…ç½®æ­£ç¡®

---

**ç¥å®éªŒé¡ºåˆ©ï¼ğŸ‰**
